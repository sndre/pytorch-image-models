{"cells":[{"cell_type":"markdown","id":"sF8bvU6yG_F7","metadata":{"id":"sF8bvU6yG_F7"},"source":["# Connect to Drive"]},{"cell_type":"code","execution_count":1,"id":"Wkd8yo2CHDuJ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17173,"status":"ok","timestamp":1717216459951,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"},"user_tz":420},"id":"Wkd8yo2CHDuJ","outputId":"2de16a80-2f36-4a73-a90d-9c9f55be2241"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/colab/pytorch-image-models\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'colab/cs231n/assignments/assignment3/'\n","FOLDERNAME = 'colab/pytorch-image-models/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"code","execution_count":2,"id":"lID9DF_66UVi","metadata":{"id":"lID9DF_66UVi","executionInfo":{"status":"ok","timestamp":1717216460415,"user_tz":420,"elapsed":465,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"id":"1QGlLwWxBthc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1717216460606,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"},"user_tz":420},"id":"1QGlLwWxBthc","outputId":"62752cdd-ef6a-464a-ccd0-d1f08d316339"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}],"source":["!python --version"]},{"cell_type":"markdown","id":"ov8Evcjh4v7T","metadata":{"id":"ov8Evcjh4v7T"},"source":["# Validate Google ViT Model"]},{"cell_type":"code","execution_count":null,"id":"KEM3Kfnl44Ij","metadata":{"id":"KEM3Kfnl44Ij"},"outputs":[],"source":["!pip install -e .\n","!pip install ml_collections\n","!pip install coremltools"]},{"cell_type":"code","execution_count":null,"id":"WZqNH-HK41G4","metadata":{"id":"WZqNH-HK41G4"},"outputs":[],"source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"]},{"cell_type":"code","source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQZVzDtVkrcZ","executionInfo":{"status":"ok","timestamp":1717141697706,"user_tz":420,"elapsed":761424,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"a6d6a0c8-dcd9-4cfd-89ae-659b046db10f"},"id":"fQZVzDtVkrcZ","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-05-31 07:35:44.996124: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-31 07:35:44.996177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-31 07:35:45.003228: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-31 07:35:45.019106: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-31 07:35:46.341191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [False, False, False, False, False, False, True, True, True, True, True, True]\n","Skipping slicing for layer 0\n","Skipping slicing for layer 1\n","Skipping slicing for layer 2\n","Skipping slicing for layer 3\n","Skipping slicing for layer 4\n","Skipping slicing for layer 5\n","Skipping slicing for layer 6\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 81145000\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 12.829s (12.829s,   19.96/s)  Loss:  0.3294 (0.3294)  Acc@1:  90.625 ( 90.625)  Acc@5:  99.609 ( 99.609)\n","Test: [  10/196]  Time: 2.991s (4.733s,   54.09/s)  Loss:  0.6555 (0.4894)  Acc@1:  83.203 ( 85.902)  Acc@5:  95.312 ( 97.656)\n","Test: [  20/196]  Time: 2.791s (4.214s,   60.74/s)  Loss:  0.4241 (0.5136)  Acc@1:  92.188 ( 85.342)  Acc@5:  97.656 ( 97.470)\n","Test: [  30/196]  Time: 2.857s (3.978s,   64.36/s)  Loss:  0.6272 (0.4785)  Acc@1:  82.422 ( 86.454)  Acc@5:  96.875 ( 97.732)\n","Test: [  40/196]  Time: 2.862s (3.838s,   66.69/s)  Loss:  0.6821 (0.5565)  Acc@1:  83.203 ( 84.356)  Acc@5:  96.094 ( 97.389)\n","Test: [  50/196]  Time: 3.032s (3.754s,   68.19/s)  Loss:  0.5244 (0.5961)  Acc@1:  86.328 ( 83.257)  Acc@5:  96.875 ( 97.105)\n","Test: [  60/196]  Time: 3.282s (3.732s,   68.59/s)  Loss:  1.1017 (0.6304)  Acc@1:  71.094 ( 82.166)  Acc@5:  91.797 ( 96.945)\n","Test: [  70/196]  Time: 3.146s (3.697s,   69.24/s)  Loss:  0.6129 (0.6238)  Acc@1:  82.422 ( 82.411)  Acc@5:  98.438 ( 97.013)\n","Test: [  80/196]  Time: 2.951s (3.676s,   69.65/s)  Loss:  1.7930 (0.6637)  Acc@1:  57.422 ( 81.665)  Acc@5:  85.156 ( 96.581)\n","Test: [  90/196]  Time: 2.894s (3.670s,   69.76/s)  Loss:  1.4966 (0.7377)  Acc@1:  63.672 ( 80.160)  Acc@5:  86.328 ( 95.725)\n","Test: [ 100/196]  Time: 3.372s (3.666s,   69.83/s)  Loss:  1.2067 (0.8203)  Acc@1:  70.312 ( 78.605)  Acc@5:  89.062 ( 94.740)\n","Test: [ 110/196]  Time: 2.831s (3.655s,   70.04/s)  Loss:  0.7864 (0.8618)  Acc@1:  80.469 ( 77.794)  Acc@5:  94.141 ( 94.345)\n","Test: [ 120/196]  Time: 2.850s (3.634s,   70.44/s)  Loss:  1.5944 (0.8992)  Acc@1:  62.891 ( 77.179)  Acc@5:  87.109 ( 93.937)\n","Test: [ 130/196]  Time: 2.843s (3.621s,   70.70/s)  Loss:  0.6626 (0.9473)  Acc@1:  85.156 ( 76.145)  Acc@5:  97.266 ( 93.377)\n","Test: [ 140/196]  Time: 2.833s (3.607s,   70.98/s)  Loss:  1.0436 (0.9703)  Acc@1:  78.125 ( 75.803)  Acc@5:  90.625 ( 93.129)\n","Test: [ 150/196]  Time: 2.843s (3.588s,   71.35/s)  Loss:  1.1889 (1.0005)  Acc@1:  74.609 ( 75.269)  Acc@5:  88.281 ( 92.697)\n","Test: [ 160/196]  Time: 2.859s (3.581s,   71.49/s)  Loss:  1.0608 (1.0135)  Acc@1:  79.297 ( 75.010)  Acc@5:  90.625 ( 92.561)\n","Test: [ 170/196]  Time: 2.832s (3.584s,   71.44/s)  Loss:  0.8053 (1.0348)  Acc@1:  80.859 ( 74.559)  Acc@5:  93.359 ( 92.352)\n","Test: [ 180/196]  Time: 2.858s (3.575s,   71.61/s)  Loss:  1.7343 (1.0535)  Acc@1:  58.203 ( 74.195)  Acc@5:  86.328 ( 92.172)\n","Test: [ 190/196]  Time: 3.348s (3.563s,   71.85/s)  Loss:  0.8906 (1.0597)  Acc@1:  75.391 ( 74.133)  Acc@5:  97.656 ( 92.112)\n"," * Acc@1 74.320 (25.680) Acc@5 92.194 (7.806)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 74.32,\n","    \"top1_err\": 25.68,\n","    \"top5\": 92.194,\n","    \"top5_err\": 7.806,\n","    \"param_count\": 81.14,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zqpa3CwUolOo","executionInfo":{"status":"ok","timestamp":1717142680674,"user_tz":420,"elapsed":758175,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"84dfe0d1-b8a1-4520-b1d5-af7a36294073"},"id":"Zqpa3CwUolOo","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-05-31 07:52:11.437181: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-31 07:52:11.437234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-31 07:52:11.444126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-31 07:52:11.461272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-31 07:52:13.299494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [True, True, True, True, True, True, True, True, True, True, True, False]\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 74174248\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 12.650s (12.650s,   20.24/s)  Loss:  0.3172 (0.3172)  Acc@1:  92.188 ( 92.188)  Acc@5:  99.609 ( 99.609)\n","Test: [  10/196]  Time: 2.603s (4.448s,   57.55/s)  Loss:  0.6668 (0.5027)  Acc@1:  82.812 ( 85.582)  Acc@5:  95.312 ( 97.479)\n","Test: [  20/196]  Time: 2.775s (3.972s,   64.46/s)  Loss:  0.4492 (0.5254)  Acc@1:  90.234 ( 84.989)  Acc@5:  97.656 ( 97.396)\n","Test: [  30/196]  Time: 2.797s (3.811s,   67.17/s)  Loss:  0.6583 (0.4909)  Acc@1:  82.422 ( 86.026)  Acc@5:  96.484 ( 97.669)\n","Test: [  40/196]  Time: 2.711s (3.766s,   67.98/s)  Loss:  0.6737 (0.5708)  Acc@1:  83.203 ( 83.775)  Acc@5:  95.703 ( 97.247)\n","Test: [  50/196]  Time: 3.629s (3.688s,   69.42/s)  Loss:  0.5451 (0.6078)  Acc@1:  85.156 ( 82.744)  Acc@5:  96.875 ( 96.944)\n","Test: [  60/196]  Time: 4.398s (3.670s,   69.76/s)  Loss:  1.0877 (0.6401)  Acc@1:  71.484 ( 81.775)  Acc@5:  90.234 ( 96.785)\n","Test: [  70/196]  Time: 3.832s (3.626s,   70.59/s)  Loss:  0.6065 (0.6327)  Acc@1:  83.594 ( 82.075)  Acc@5:  98.828 ( 96.864)\n","Test: [  80/196]  Time: 3.278s (3.610s,   70.91/s)  Loss:  1.7257 (0.6711)  Acc@1:  57.812 ( 81.404)  Acc@5:  85.938 ( 96.446)\n","Test: [  90/196]  Time: 3.104s (3.598s,   71.15/s)  Loss:  1.4514 (0.7412)  Acc@1:  65.625 ( 79.949)  Acc@5:  87.109 ( 95.630)\n","Test: [ 100/196]  Time: 4.088s (3.581s,   71.48/s)  Loss:  1.2073 (0.8235)  Acc@1:  68.750 ( 78.295)  Acc@5:  88.281 ( 94.643)\n","Test: [ 110/196]  Time: 2.863s (3.564s,   71.83/s)  Loss:  0.8217 (0.8669)  Acc@1:  80.078 ( 77.379)  Acc@5:  92.969 ( 94.200)\n","Test: [ 120/196]  Time: 3.804s (3.585s,   71.40/s)  Loss:  1.6123 (0.9053)  Acc@1:  61.328 ( 76.792)  Acc@5:  85.938 ( 93.724)\n","Test: [ 130/196]  Time: 2.741s (3.569s,   71.73/s)  Loss:  0.6678 (0.9516)  Acc@1:  83.594 ( 75.766)  Acc@5:  95.703 ( 93.151)\n","Test: [ 140/196]  Time: 4.159s (3.560s,   71.92/s)  Loss:  1.0240 (0.9737)  Acc@1:  76.562 ( 75.432)  Acc@5:  93.750 ( 92.913)\n","Test: [ 150/196]  Time: 5.224s (3.551s,   72.10/s)  Loss:  1.2477 (1.0041)  Acc@1:  75.000 ( 74.897)  Acc@5:  87.891 ( 92.469)\n","Test: [ 160/196]  Time: 4.745s (3.542s,   72.27/s)  Loss:  1.1030 (1.0176)  Acc@1:  74.219 ( 74.585)  Acc@5:  90.234 ( 92.338)\n","Test: [ 170/196]  Time: 5.714s (3.537s,   72.38/s)  Loss:  0.8634 (1.0391)  Acc@1:  78.125 ( 74.086)  Acc@5:  92.969 ( 92.137)\n","Test: [ 180/196]  Time: 5.260s (3.531s,   72.50/s)  Loss:  1.7617 (1.0573)  Acc@1:  56.250 ( 73.694)  Acc@5:  86.328 ( 91.954)\n","Test: [ 190/196]  Time: 5.067s (3.524s,   72.65/s)  Loss:  0.9744 (1.0648)  Acc@1:  73.828 ( 73.593)  Acc@5:  96.875 ( 91.887)\n"," * Acc@1 73.776 (26.224) Acc@5 91.962 (8.038)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 73.776,\n","    \"top1_err\": 26.224,\n","    \"top5\": 91.962,\n","    \"top5_err\": 8.038,\n","    \"param_count\": 74.17,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ok5ShxODomGu","executionInfo":{"status":"ok","timestamp":1717143504533,"user_tz":420,"elapsed":782521,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"5950d895-dd51-4e31-b916-292ac4d17732"},"id":"Ok5ShxODomGu","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-05-31 08:05:31.652221: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-31 08:05:31.652287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-31 08:05:31.659000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-31 08:05:31.679069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-31 08:05:33.741097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [True, True, True, True, True, True, True, True, True, False, False, False]\n","Skipping slicing for layer 10\n","Skipping slicing for layer 11\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 76386856\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 12.825s (12.825s,   19.96/s)  Loss:  0.3339 (0.3339)  Acc@1:  91.016 ( 91.016)  Acc@5:  99.219 ( 99.219)\n","Test: [  10/196]  Time: 2.825s (4.855s,   52.73/s)  Loss:  0.7250 (0.5034)  Acc@1:  80.078 ( 85.973)  Acc@5:  95.312 ( 97.550)\n","Test: [  20/196]  Time: 2.748s (4.211s,   60.80/s)  Loss:  0.5038 (0.5305)  Acc@1:  89.844 ( 85.342)  Acc@5:  96.484 ( 97.377)\n","Test: [  30/196]  Time: 2.765s (4.013s,   63.79/s)  Loss:  0.6658 (0.4956)  Acc@1:  82.812 ( 86.240)  Acc@5:  96.094 ( 97.543)\n","Test: [  40/196]  Time: 2.808s (3.949s,   64.82/s)  Loss:  0.6237 (0.5740)  Acc@1:  84.375 ( 83.975)  Acc@5:  95.312 ( 97.142)\n","Test: [  50/196]  Time: 3.177s (3.862s,   66.28/s)  Loss:  0.4422 (0.5948)  Acc@1:  88.672 ( 83.509)  Acc@5:  96.484 ( 96.982)\n","Test: [  60/196]  Time: 3.629s (3.839s,   66.68/s)  Loss:  0.7653 (0.6132)  Acc@1:  76.562 ( 82.992)  Acc@5:  94.922 ( 97.003)\n","Test: [  70/196]  Time: 2.828s (3.787s,   67.60/s)  Loss:  0.5799 (0.5985)  Acc@1:  86.328 ( 83.456)  Acc@5:  98.828 ( 97.156)\n","Test: [  80/196]  Time: 3.429s (3.781s,   67.71/s)  Loss:  1.2968 (0.6203)  Acc@1:  63.672 ( 83.083)  Acc@5:  89.844 ( 96.899)\n","Test: [  90/196]  Time: 2.801s (3.766s,   67.98/s)  Loss:  1.3781 (0.6636)  Acc@1:  64.844 ( 82.070)  Acc@5:  88.281 ( 96.356)\n","Test: [ 100/196]  Time: 3.186s (3.742s,   68.42/s)  Loss:  0.8811 (0.7193)  Acc@1:  75.781 ( 80.840)  Acc@5:  93.750 ( 95.808)\n","Test: [ 110/196]  Time: 2.750s (3.748s,   68.29/s)  Loss:  0.6106 (0.7442)  Acc@1:  84.766 ( 80.370)  Acc@5:  95.703 ( 95.576)\n","Test: [ 120/196]  Time: 2.821s (3.746s,   68.33/s)  Loss:  1.3153 (0.7644)  Acc@1:  70.312 ( 80.046)  Acc@5:  91.016 ( 95.367)\n","Test: [ 130/196]  Time: 2.758s (3.728s,   68.68/s)  Loss:  0.5657 (0.7961)  Acc@1:  82.422 ( 79.193)  Acc@5:  97.266 ( 95.056)\n","Test: [ 140/196]  Time: 2.760s (3.705s,   69.10/s)  Loss:  0.8639 (0.8124)  Acc@1:  78.906 ( 78.826)  Acc@5:  94.141 ( 94.900)\n","Test: [ 150/196]  Time: 4.268s (3.687s,   69.43/s)  Loss:  1.0440 (0.8342)  Acc@1:  76.953 ( 78.451)  Acc@5:  90.234 ( 94.555)\n","Test: [ 160/196]  Time: 4.039s (3.670s,   69.75/s)  Loss:  0.7111 (0.8435)  Acc@1:  82.422 ( 78.239)  Acc@5:  94.141 ( 94.412)\n","Test: [ 170/196]  Time: 4.214s (3.655s,   70.05/s)  Loss:  0.6418 (0.8607)  Acc@1:  81.250 ( 77.803)  Acc@5:  95.703 ( 94.275)\n","Test: [ 180/196]  Time: 4.240s (3.642s,   70.28/s)  Loss:  1.2734 (0.8729)  Acc@1:  66.797 ( 77.514)  Acc@5:  93.359 ( 94.177)\n","Test: [ 190/196]  Time: 4.725s (3.646s,   70.22/s)  Loss:  0.9648 (0.8739)  Acc@1:  75.781 ( 77.509)  Acc@5:  96.875 ( 94.186)\n"," * Acc@1 77.654 (22.346) Acc@5 94.224 (5.776)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 77.654,\n","    \"top1_err\": 22.346,\n","    \"top5\": 94.224,\n","    \"top5_err\": 5.776,\n","    \"param_count\": 76.39,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pvK7jcIrpPv","executionInfo":{"status":"ok","timestamp":1717144305473,"user_tz":420,"elapsed":762925,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"c2656224-463f-4ca3-eda0-b4802c441945"},"id":"8pvK7jcIrpPv","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-05-31 08:19:11.745215: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-31 08:19:11.745274: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-31 08:19:11.752568: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-31 08:19:11.770828: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-31 08:19:13.709079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [True, True, True, True, True, True, True, True, True, True, False, False]\n","Skipping slicing for layer 11\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 75280552\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 11.703s (11.703s,   21.88/s)  Loss:  0.3218 (0.3218)  Acc@1:  91.016 ( 91.016)  Acc@5:  99.219 ( 99.219)\n","Test: [  10/196]  Time: 2.890s (4.370s,   58.58/s)  Loss:  0.6760 (0.5021)  Acc@1:  81.641 ( 85.511)  Acc@5:  95.312 ( 97.585)\n","Test: [  20/196]  Time: 2.793s (3.916s,   65.37/s)  Loss:  0.4805 (0.5305)  Acc@1:  89.844 ( 85.063)  Acc@5:  97.656 ( 97.433)\n","Test: [  30/196]  Time: 2.875s (3.789s,   67.57/s)  Loss:  0.6769 (0.4954)  Acc@1:  81.641 ( 86.038)  Acc@5:  96.484 ( 97.656)\n","Test: [  40/196]  Time: 3.381s (3.742s,   68.42/s)  Loss:  0.6780 (0.5747)  Acc@1:  83.594 ( 83.756)  Acc@5:  94.922 ( 97.237)\n","Test: [  50/196]  Time: 4.288s (3.677s,   69.62/s)  Loss:  0.4901 (0.6033)  Acc@1:  87.500 ( 83.211)  Acc@5:  96.875 ( 97.005)\n","Test: [  60/196]  Time: 5.223s (3.681s,   69.55/s)  Loss:  0.9488 (0.6271)  Acc@1:  74.219 ( 82.576)  Acc@5:  92.969 ( 96.952)\n","Test: [  70/196]  Time: 4.629s (3.634s,   70.44/s)  Loss:  0.6086 (0.6168)  Acc@1:  84.766 ( 82.906)  Acc@5:  98.828 ( 97.029)\n","Test: [  80/196]  Time: 4.307s (3.615s,   70.81/s)  Loss:  1.4241 (0.6459)  Acc@1:  62.891 ( 82.388)  Acc@5:  89.062 ( 96.697)\n","Test: [  90/196]  Time: 3.546s (3.596s,   71.19/s)  Loss:  1.4195 (0.7017)  Acc@1:  62.500 ( 81.078)  Acc@5:  89.453 ( 96.034)\n","Test: [ 100/196]  Time: 4.867s (3.584s,   71.43/s)  Loss:  0.9933 (0.7702)  Acc@1:  73.828 ( 79.587)  Acc@5:  92.578 ( 95.309)\n","Test: [ 110/196]  Time: 3.563s (3.585s,   71.42/s)  Loss:  0.7227 (0.8047)  Acc@1:  80.859 ( 78.818)  Acc@5:  93.750 ( 94.992)\n","Test: [ 120/196]  Time: 4.637s (3.585s,   71.42/s)  Loss:  1.4262 (0.8312)  Acc@1:  67.578 ( 78.367)  Acc@5:  89.062 ( 94.657)\n","Test: [ 130/196]  Time: 2.765s (3.561s,   71.89/s)  Loss:  0.6107 (0.8679)  Acc@1:  83.594 ( 77.490)  Acc@5:  95.703 ( 94.245)\n","Test: [ 140/196]  Time: 3.960s (3.560s,   71.92/s)  Loss:  0.9264 (0.8852)  Acc@1:  76.953 ( 77.161)  Acc@5:  94.141 ( 94.046)\n","Test: [ 150/196]  Time: 5.014s (3.560s,   71.91/s)  Loss:  1.1287 (0.9096)  Acc@1:  76.562 ( 76.749)  Acc@5:  89.844 ( 93.680)\n","Test: [ 160/196]  Time: 4.944s (3.558s,   71.95/s)  Loss:  0.8583 (0.9207)  Acc@1:  77.734 ( 76.446)  Acc@5:  91.406 ( 93.515)\n","Test: [ 170/196]  Time: 4.496s (3.548s,   72.16/s)  Loss:  0.7596 (0.9409)  Acc@1:  79.688 ( 75.964)  Acc@5:  94.922 ( 93.321)\n","Test: [ 180/196]  Time: 6.318s (3.553s,   72.06/s)  Loss:  1.4020 (0.9554)  Acc@1:  63.672 ( 75.619)  Acc@5:  92.578 ( 93.210)\n","Test: [ 190/196]  Time: 4.756s (3.546s,   72.19/s)  Loss:  0.9644 (0.9587)  Acc@1:  74.219 ( 75.589)  Acc@5:  96.875 ( 93.206)\n"," * Acc@1 75.768 (24.232) Acc@5 93.260 (6.740)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 75.768,\n","    \"top1_err\": 24.232,\n","    \"top5\": 93.26,\n","    \"top5_err\": 6.74,\n","    \"param_count\": 75.28,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVx1Ou9ayAGN","executionInfo":{"status":"ok","timestamp":1717145167091,"user_tz":420,"elapsed":776138,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"1b567186-2dce-4425-ab11-351ca0acea59"},"id":"tVx1Ou9ayAGN","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-05-31 08:33:19.777668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-31 08:33:19.777728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-31 08:33:19.785343: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-31 08:33:19.808722: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-31 08:33:22.148941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [True, True, True, True, True, True, True, True, True, False, True, False]\n","Skipping slicing for layer 10\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 75833512\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 12.763s (12.763s,   20.06/s)  Loss:  0.3197 (0.3197)  Acc@1:  92.578 ( 92.578)  Acc@5:  99.609 ( 99.609)\n","Test: [  10/196]  Time: 2.812s (4.521s,   56.63/s)  Loss:  0.6979 (0.5022)  Acc@1:  80.078 ( 85.795)  Acc@5:  95.312 ( 97.621)\n","Test: [  20/196]  Time: 2.834s (4.097s,   62.49/s)  Loss:  0.4567 (0.5222)  Acc@1:  90.234 ( 85.193)  Acc@5:  97.656 ( 97.396)\n","Test: [  30/196]  Time: 2.731s (3.885s,   65.90/s)  Loss:  0.6549 (0.4879)  Acc@1:  82.031 ( 86.164)  Acc@5:  96.484 ( 97.644)\n","Test: [  40/196]  Time: 2.821s (3.767s,   67.96/s)  Loss:  0.6313 (0.5654)  Acc@1:  84.375 ( 84.070)  Acc@5:  95.703 ( 97.266)\n","Test: [  50/196]  Time: 3.063s (3.689s,   69.40/s)  Loss:  0.5060 (0.5992)  Acc@1:  87.500 ( 83.234)  Acc@5:  97.266 ( 96.959)\n","Test: [  60/196]  Time: 3.410s (3.672s,   69.71/s)  Loss:  0.9750 (0.6278)  Acc@1:  75.000 ( 82.383)  Acc@5:  91.016 ( 96.875)\n","Test: [  70/196]  Time: 2.999s (3.641s,   70.30/s)  Loss:  0.5896 (0.6188)  Acc@1:  85.156 ( 82.713)  Acc@5:  98.828 ( 96.963)\n","Test: [  80/196]  Time: 3.030s (3.635s,   70.42/s)  Loss:  1.6344 (0.6536)  Acc@1:  59.375 ( 82.075)  Acc@5:  87.891 ( 96.605)\n","Test: [  90/196]  Time: 3.285s (3.644s,   70.24/s)  Loss:  1.4175 (0.7166)  Acc@1:  66.797 ( 80.765)  Acc@5:  87.500 ( 95.879)\n","Test: [ 100/196]  Time: 3.199s (3.631s,   70.51/s)  Loss:  1.1451 (0.7919)  Acc@1:  69.922 ( 79.216)  Acc@5:  90.625 ( 95.042)\n","Test: [ 110/196]  Time: 2.770s (3.624s,   70.65/s)  Loss:  0.7814 (0.8302)  Acc@1:  81.250 ( 78.385)  Acc@5:  94.141 ( 94.668)\n","Test: [ 120/196]  Time: 3.112s (3.624s,   70.65/s)  Loss:  1.5578 (0.8651)  Acc@1:  62.109 ( 77.818)  Acc@5:  86.328 ( 94.225)\n","Test: [ 130/196]  Time: 2.752s (3.614s,   70.84/s)  Loss:  0.6326 (0.9087)  Acc@1:  83.203 ( 76.843)  Acc@5:  96.875 ( 93.735)\n","Test: [ 140/196]  Time: 3.126s (3.605s,   71.02/s)  Loss:  0.9785 (0.9293)  Acc@1:  78.125 ( 76.502)  Acc@5:  93.750 ( 93.531)\n","Test: [ 150/196]  Time: 3.548s (3.599s,   71.14/s)  Loss:  1.1782 (0.9573)  Acc@1:  75.781 ( 76.006)  Acc@5:  88.672 ( 93.137)\n","Test: [ 160/196]  Time: 3.391s (3.610s,   70.92/s)  Loss:  1.0082 (0.9693)  Acc@1:  77.344 ( 75.730)  Acc@5:  91.797 ( 93.012)\n","Test: [ 170/196]  Time: 3.131s (3.602s,   71.07/s)  Loss:  0.7579 (0.9894)  Acc@1:  80.078 ( 75.249)  Acc@5:  93.750 ( 92.816)\n","Test: [ 180/196]  Time: 3.172s (3.594s,   71.24/s)  Loss:  1.6695 (1.0063)  Acc@1:  58.203 ( 74.905)  Acc@5:  88.672 ( 92.647)\n","Test: [ 190/196]  Time: 3.268s (3.589s,   71.32/s)  Loss:  0.9635 (1.0121)  Acc@1:  73.438 ( 74.824)  Acc@5:  96.875 ( 92.590)\n"," * Acc@1 74.990 (25.010) Acc@5 92.660 (7.340)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 74.99,\n","    \"top1_err\": 25.01,\n","    \"top5\": 92.66,\n","    \"top5_err\": 7.34,\n","    \"param_count\": 75.83,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKDUfpMWyAwn","executionInfo":{"status":"ok","timestamp":1717211039927,"user_tz":420,"elapsed":9446178,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"e41e7caa-9bec-4d87-8775-10e3bbec3059"},"id":"wKDUfpMWyAwn","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-06-01 00:27:27.551571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 00:27:27.551616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 00:27:27.667745: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-01 00:27:27.894820: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-01 00:27:29.161332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","model.safetensors: 100% 346M/346M [00:09<00:00, 38.4MB/s]\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [True, True, True, True, True, True, True, False, False, False, False, False]\n","Skipping slicing for layer 8\n","Skipping slicing for layer 9\n","Skipping slicing for layer 10\n","Skipping slicing for layer 11\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 78599464\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 102.452s (102.452s,    2.50/s)  Loss:  0.3104 (0.3104)  Acc@1:  92.578 ( 92.578)  Acc@5:  99.219 ( 99.219)\n","Test: [  10/196]  Time: 5.234s (53.814s,    4.76/s)  Loss:  0.7299 (0.4919)  Acc@1:  80.078 ( 86.506)  Acc@5:  96.484 ( 97.621)\n","Test: [  20/196]  Time: 2.993s (51.601s,    4.96/s)  Loss:  0.5390 (0.5201)  Acc@1:  89.062 ( 86.142)  Acc@5:  96.094 ( 97.321)\n","Test: [  30/196]  Time: 3.099s (50.335s,    5.09/s)  Loss:  0.6760 (0.4846)  Acc@1:  82.422 ( 87.046)  Acc@5:  96.094 ( 97.467)\n","Test: [  40/196]  Time: 8.334s (49.815s,    5.14/s)  Loss:  0.5862 (0.5587)  Acc@1:  85.938 ( 84.880)  Acc@5:  95.312 ( 97.094)\n","Test: [  50/196]  Time: 22.914s (49.699s,    5.15/s)  Loss:  0.4118 (0.5757)  Acc@1:  90.234 ( 84.421)  Acc@5:  96.094 ( 97.005)\n","Test: [  60/196]  Time: 31.104s (49.592s,    5.16/s)  Loss:  0.6286 (0.5893)  Acc@1:  81.250 ( 84.048)  Acc@5:  95.703 ( 97.074)\n","Test: [  70/196]  Time: 23.213s (49.376s,    5.18/s)  Loss:  0.5679 (0.5728)  Acc@1:  84.766 ( 84.502)  Acc@5:  99.219 ( 97.260)\n","Test: [  80/196]  Time: 18.387s (49.148s,    5.21/s)  Loss:  1.0947 (0.5854)  Acc@1:  69.531 ( 84.303)  Acc@5:  92.969 ( 97.121)\n","Test: [  90/196]  Time: 24.757s (48.986s,    5.23/s)  Loss:  1.2530 (0.6126)  Acc@1:  65.234 ( 83.671)  Acc@5:  92.188 ( 96.828)\n","Test: [ 100/196]  Time: 35.756s (48.945s,    5.23/s)  Loss:  0.8108 (0.6527)  Acc@1:  78.125 ( 82.774)  Acc@5:  93.750 ( 96.477)\n","Test: [ 110/196]  Time: 39.618s (48.787s,    5.25/s)  Loss:  0.5446 (0.6659)  Acc@1:  85.938 ( 82.471)  Acc@5:  96.484 ( 96.400)\n","Test: [ 120/196]  Time: 41.171s (48.737s,    5.25/s)  Loss:  1.0812 (0.6769)  Acc@1:  75.391 ( 82.309)  Acc@5:  93.359 ( 96.262)\n","Test: [ 130/196]  Time: 35.061s (48.647s,    5.26/s)  Loss:  0.5089 (0.7004)  Acc@1:  84.375 ( 81.620)  Acc@5:  97.656 ( 96.076)\n","Test: [ 140/196]  Time: 39.587s (48.614s,    5.27/s)  Loss:  0.7001 (0.7107)  Acc@1:  82.422 ( 81.397)  Acc@5:  95.312 ( 95.958)\n","Test: [ 150/196]  Time: 28.665s (48.493s,    5.28/s)  Loss:  0.8034 (0.7268)  Acc@1:  82.812 ( 81.074)  Acc@5:  93.359 ( 95.737)\n","Test: [ 160/196]  Time: 33.002s (48.418s,    5.29/s)  Loss:  0.6032 (0.7350)  Acc@1:  85.547 ( 80.893)  Acc@5:  96.094 ( 95.628)\n","Test: [ 170/196]  Time: 33.386s (48.299s,    5.30/s)  Loss:  0.4821 (0.7480)  Acc@1:  83.203 ( 80.533)  Acc@5:  97.266 ( 95.509)\n","Test: [ 180/196]  Time: 37.138s (48.201s,    5.31/s)  Loss:  0.9688 (0.7578)  Acc@1:  73.438 ( 80.281)  Acc@5:  94.922 ( 95.446)\n","Test: [ 190/196]  Time: 40.770s (48.102s,    5.32/s)  Loss:  0.9951 (0.7564)  Acc@1:  73.047 ( 80.319)  Acc@5:  96.875 ( 95.466)\n"," * Acc@1 80.418 (19.582) Acc@5 95.502 (4.498)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 80.418,\n","    \"top1_err\": 19.582,\n","    \"top5\": 95.502,\n","    \"top5_err\": 4.498,\n","    \"param_count\": 78.6,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAldPUOPMORP","executionInfo":{"status":"ok","timestamp":1717211896221,"user_tz":420,"elapsed":745461,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"c8df9eb9-c581-442c-f311-935ef4f708fd"},"id":"bAldPUOPMORP","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-06-01 03:05:59.368505: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 03:05:59.368555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 03:05:59.374279: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-01 03:05:59.391798: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-01 03:06:00.881442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [True, True, True, True, True, True, True, True, False, False, False, False]\n","Skipping slicing for layer 9\n","Skipping slicing for layer 10\n","Skipping slicing for layer 11\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 77493160\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 13.165s (13.165s,   19.45/s)  Loss:  0.3121 (0.3121)  Acc@1:  92.578 ( 92.578)  Acc@5:  99.609 ( 99.609)\n","Test: [  10/196]  Time: 2.495s (4.467s,   57.31/s)  Loss:  0.7440 (0.5009)  Acc@1:  80.469 ( 86.435)  Acc@5:  96.875 ( 97.479)\n","Test: [  20/196]  Time: 2.624s (3.920s,   65.31/s)  Loss:  0.5288 (0.5289)  Acc@1:  89.453 ( 85.863)  Acc@5:  95.703 ( 97.266)\n","Test: [  30/196]  Time: 2.715s (3.714s,   68.93/s)  Loss:  0.6962 (0.4943)  Acc@1:  82.031 ( 86.769)  Acc@5:  96.484 ( 97.467)\n","Test: [  40/196]  Time: 2.738s (3.665s,   69.86/s)  Loss:  0.6162 (0.5674)  Acc@1:  83.594 ( 84.527)  Acc@5:  96.094 ( 97.132)\n","Test: [  50/196]  Time: 3.044s (3.576s,   71.59/s)  Loss:  0.4140 (0.5855)  Acc@1:  89.453 ( 84.030)  Acc@5:  96.875 ( 97.013)\n","Test: [  60/196]  Time: 3.631s (3.569s,   71.72/s)  Loss:  0.6869 (0.5996)  Acc@1:  78.906 ( 83.651)  Acc@5:  95.703 ( 97.106)\n","Test: [  70/196]  Time: 2.978s (3.541s,   72.29/s)  Loss:  0.5867 (0.5836)  Acc@1:  85.156 ( 84.133)  Acc@5:  98.828 ( 97.271)\n","Test: [  80/196]  Time: 3.154s (3.554s,   72.02/s)  Loss:  1.1783 (0.5999)  Acc@1:  67.188 ( 83.902)  Acc@5:  93.359 ( 97.106)\n","Test: [  90/196]  Time: 3.012s (3.538s,   72.35/s)  Loss:  1.3086 (0.6341)  Acc@1:  62.500 ( 83.070)  Acc@5:  90.234 ( 96.708)\n","Test: [ 100/196]  Time: 3.124s (3.514s,   72.86/s)  Loss:  0.8476 (0.6789)  Acc@1:  78.516 ( 82.082)  Acc@5:  92.969 ( 96.272)\n","Test: [ 110/196]  Time: 3.064s (3.506s,   73.03/s)  Loss:  0.5635 (0.6976)  Acc@1:  85.156 ( 81.669)  Acc@5:  96.484 ( 96.090)\n","Test: [ 120/196]  Time: 3.023s (3.510s,   72.93/s)  Loss:  1.2092 (0.7124)  Acc@1:  69.922 ( 81.415)  Acc@5:  92.578 ( 95.939)\n","Test: [ 130/196]  Time: 3.039s (3.501s,   73.11/s)  Loss:  0.5260 (0.7395)  Acc@1:  81.641 ( 80.683)  Acc@5:  98.047 ( 95.667)\n","Test: [ 140/196]  Time: 3.039s (3.490s,   73.36/s)  Loss:  0.7672 (0.7523)  Acc@1:  80.859 ( 80.422)  Acc@5:  94.531 ( 95.523)\n","Test: [ 150/196]  Time: 2.998s (3.488s,   73.40/s)  Loss:  0.8929 (0.7704)  Acc@1:  80.859 ( 80.107)  Acc@5:  91.797 ( 95.245)\n","Test: [ 160/196]  Time: 2.987s (3.479s,   73.59/s)  Loss:  0.6440 (0.7795)  Acc@1:  83.984 ( 79.899)  Acc@5:  95.312 ( 95.131)\n","Test: [ 170/196]  Time: 2.990s (3.467s,   73.83/s)  Loss:  0.5525 (0.7941)  Acc@1:  82.422 ( 79.516)  Acc@5:  96.094 ( 95.011)\n","Test: [ 180/196]  Time: 3.001s (3.458s,   74.03/s)  Loss:  1.0769 (0.8047)  Acc@1:  70.312 ( 79.245)  Acc@5:  93.750 ( 94.939)\n","Test: [ 190/196]  Time: 2.972s (3.458s,   74.03/s)  Loss:  0.9671 (0.8033)  Acc@1:  75.391 ( 79.291)  Acc@5:  96.484 ( 94.965)\n"," * Acc@1 79.398 (20.602) Acc@5 95.000 (5.000)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 79.398,\n","    \"top1_err\": 20.602,\n","    \"top5\": 95.0,\n","    \"top5_err\": 5.0,\n","    \"param_count\": 77.49,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["# [False, False, False, False, False, False, False, False, False, False, False, True]\n","!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HyKctWODwrg6","executionInfo":{"status":"ok","timestamp":1717223381337,"user_tz":420,"elapsed":6405767,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"a66a317f-9c5c-409f-c652-e6b983771beb"},"id":"HyKctWODwrg6","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-06-01 04:43:56.262542: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 04:43:56.262595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 04:43:56.376980: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-01 04:43:56.598451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-01 04:43:57.947554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","model.safetensors: 100% 346M/346M [00:07<00:00, 43.8MB/s]\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [False, False, False, False, False, False, False, False, False, False, False, True]\n","Skipping slicing for layer 0\n","Skipping slicing for layer 1\n","Skipping slicing for layer 2\n","Skipping slicing for layer 3\n","Skipping slicing for layer 4\n","Skipping slicing for layer 5\n","Skipping slicing for layer 6\n","Skipping slicing for layer 7\n","Skipping slicing for layer 8\n","Skipping slicing for layer 9\n","Skipping slicing for layer 10\n","Skipping slicing for layer 11\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 86676520\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 73.752s (73.752s,    3.47/s)  Loss:  0.2988 (0.2988)  Acc@1:  93.359 ( 93.359)  Acc@5:  99.219 ( 99.219)\n","Test: [  10/196]  Time: 2.760s (36.827s,    6.95/s)  Loss:  0.7435 (0.4695)  Acc@1:  81.641 ( 86.825)  Acc@5:  95.312 ( 97.727)\n","Test: [  20/196]  Time: 2.867s (34.877s,    7.34/s)  Loss:  0.4863 (0.4944)  Acc@1:  90.234 ( 86.458)  Acc@5:  96.094 ( 97.414)\n","Test: [  30/196]  Time: 2.912s (33.868s,    7.56/s)  Loss:  0.6653 (0.4581)  Acc@1:  81.641 ( 87.361)  Acc@5:  95.703 ( 97.681)\n","Test: [  40/196]  Time: 9.329s (33.647s,    7.61/s)  Loss:  0.5495 (0.5240)  Acc@1:  86.328 ( 85.595)  Acc@5:  95.312 ( 97.370)\n","Test: [  50/196]  Time: 19.020s (33.499s,    7.64/s)  Loss:  0.3894 (0.5414)  Acc@1:  90.234 ( 85.179)  Acc@5:  96.875 ( 97.304)\n","Test: [  60/196]  Time: 30.023s (33.427s,    7.66/s)  Loss:  0.6678 (0.5584)  Acc@1:  80.078 ( 84.663)  Acc@5:  95.703 ( 97.342)\n","Test: [  70/196]  Time: 27.772s (33.304s,    7.69/s)  Loss:  0.5412 (0.5449)  Acc@1:  86.719 ( 85.041)  Acc@5:  99.219 ( 97.491)\n","Test: [  80/196]  Time: 26.342s (33.172s,    7.72/s)  Loss:  1.1026 (0.5597)  Acc@1:  71.094 ( 84.766)  Acc@5:  92.969 ( 97.338)\n","Test: [  90/196]  Time: 20.788s (33.058s,    7.74/s)  Loss:  1.2729 (0.5900)  Acc@1:  64.844 ( 84.156)  Acc@5:  91.016 ( 97.090)\n","Test: [ 100/196]  Time: 30.076s (33.000s,    7.76/s)  Loss:  0.8103 (0.6289)  Acc@1:  76.953 ( 83.273)  Acc@5:  93.750 ( 96.728)\n","Test: [ 110/196]  Time: 27.156s (32.842s,    7.80/s)  Loss:  0.5457 (0.6406)  Acc@1:  86.328 ( 83.073)  Acc@5:  97.656 ( 96.674)\n","Test: [ 120/196]  Time: 32.835s (32.783s,    7.81/s)  Loss:  1.0633 (0.6544)  Acc@1:  75.000 ( 82.874)  Acc@5:  93.359 ( 96.513)\n","Test: [ 130/196]  Time: 26.221s (32.744s,    7.82/s)  Loss:  0.4085 (0.6809)  Acc@1:  85.547 ( 82.168)  Acc@5:  98.828 ( 96.285)\n","Test: [ 140/196]  Time: 28.859s (32.760s,    7.81/s)  Loss:  0.7241 (0.6921)  Acc@1:  83.594 ( 81.979)  Acc@5:  94.141 ( 96.171)\n","Test: [ 150/196]  Time: 26.559s (32.745s,    7.82/s)  Loss:  0.7181 (0.7043)  Acc@1:  82.812 ( 81.762)  Acc@5:  94.141 ( 96.003)\n","Test: [ 160/196]  Time: 28.245s (32.702s,    7.83/s)  Loss:  0.6149 (0.7113)  Acc@1:  85.938 ( 81.616)  Acc@5:  96.094 ( 95.926)\n","Test: [ 170/196]  Time: 29.097s (32.629s,    7.85/s)  Loss:  0.3935 (0.7227)  Acc@1:  88.281 ( 81.346)  Acc@5:  98.438 ( 95.849)\n","Test: [ 180/196]  Time: 35.363s (32.575s,    7.86/s)  Loss:  1.0555 (0.7345)  Acc@1:  74.219 ( 81.054)  Acc@5:  94.141 ( 95.764)\n","Test: [ 190/196]  Time: 31.883s (32.492s,    7.88/s)  Loss:  0.8976 (0.7337)  Acc@1:  75.000 ( 81.080)  Acc@5:  96.484 ( 95.789)\n"," * Acc@1 81.178 (18.822) Acc@5 95.818 (4.182)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 81.178,\n","    \"top1_err\": 18.822,\n","    \"top5\": 95.818,\n","    \"top5_err\": 4.182,\n","    \"param_count\": 86.68,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["# [False, False, False, False, False, False, False, False, False, False, True, True]\n","!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kgnryUguWzdO","executionInfo":{"status":"ok","timestamp":1717224215182,"user_tz":420,"elapsed":800793,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"d127f044-4f44-4d33-d35d-86d959f3dc0e"},"id":"kgnryUguWzdO","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-06-01 06:30:23.308322: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 06:30:23.308368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 06:30:23.313556: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-01 06:30:23.328835: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-01 06:30:24.720026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [False, False, False, False, False, False, False, False, False, False, True, True]\n","Skipping slicing for layer 0\n","Skipping slicing for layer 1\n","Skipping slicing for layer 2\n","Skipping slicing for layer 3\n","Skipping slicing for layer 4\n","Skipping slicing for layer 5\n","Skipping slicing for layer 6\n","Skipping slicing for layer 7\n","Skipping slicing for layer 8\n","Skipping slicing for layer 9\n","Skipping slicing for layer 10\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 85570216\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 10.584s (10.584s,   24.19/s)  Loss:  0.2987 (0.2987)  Acc@1:  92.188 ( 92.188)  Acc@5:  98.828 ( 98.828)\n","Test: [  10/196]  Time: 3.003s (4.875s,   52.51/s)  Loss:  0.7183 (0.4701)  Acc@1:  81.250 ( 86.541)  Acc@5:  95.312 ( 97.763)\n","Test: [  20/196]  Time: 2.861s (4.319s,   59.27/s)  Loss:  0.4369 (0.4871)  Acc@1:  92.578 ( 86.235)  Acc@5:  96.875 ( 97.507)\n","Test: [  30/196]  Time: 2.943s (4.092s,   62.56/s)  Loss:  0.6358 (0.4514)  Acc@1:  82.422 ( 87.311)  Acc@5:  95.703 ( 97.707)\n","Test: [  40/196]  Time: 2.917s (3.939s,   64.99/s)  Loss:  0.5670 (0.5193)  Acc@1:  85.547 ( 85.433)  Acc@5:  95.703 ( 97.380)\n","Test: [  50/196]  Time: 3.163s (3.919s,   65.33/s)  Loss:  0.4329 (0.5473)  Acc@1:  88.281 ( 84.720)  Acc@5:  97.266 ( 97.189)\n","Test: [  60/196]  Time: 4.578s (3.898s,   65.68/s)  Loss:  0.8275 (0.5720)  Acc@1:  77.344 ( 84.029)  Acc@5:  94.922 ( 97.163)\n","Test: [  70/196]  Time: 3.289s (3.845s,   66.57/s)  Loss:  0.5527 (0.5609)  Acc@1:  85.156 ( 84.364)  Acc@5:  99.219 ( 97.310)\n","Test: [  80/196]  Time: 2.847s (3.817s,   67.06/s)  Loss:  1.4525 (0.5901)  Acc@1:  60.547 ( 83.753)  Acc@5:  89.453 ( 97.049)\n","Test: [  90/196]  Time: 2.873s (3.806s,   67.27/s)  Loss:  1.3474 (0.6362)  Acc@1:  65.234 ( 82.946)  Acc@5:  89.844 ( 96.665)\n","Test: [ 100/196]  Time: 2.879s (3.783s,   67.67/s)  Loss:  0.9279 (0.6950)  Acc@1:  78.516 ( 81.780)  Acc@5:  94.531 ( 96.129)\n","Test: [ 110/196]  Time: 2.862s (3.772s,   67.87/s)  Loss:  0.6818 (0.7162)  Acc@1:  83.203 ( 81.440)  Acc@5:  95.312 ( 95.967)\n","Test: [ 120/196]  Time: 2.896s (3.759s,   68.10/s)  Loss:  1.2713 (0.7383)  Acc@1:  69.531 ( 81.250)  Acc@5:  91.016 ( 95.732)\n","Test: [ 130/196]  Time: 2.860s (3.748s,   68.31/s)  Loss:  0.4669 (0.7743)  Acc@1:  87.109 ( 80.469)  Acc@5:  97.656 ( 95.402)\n","Test: [ 140/196]  Time: 2.895s (3.755s,   68.17/s)  Loss:  0.8285 (0.7900)  Acc@1:  84.375 ( 80.239)  Acc@5:  93.750 ( 95.265)\n","Test: [ 150/196]  Time: 2.850s (3.735s,   68.55/s)  Loss:  0.8847 (0.8077)  Acc@1:  82.422 ( 79.957)  Acc@5:  93.750 ( 95.054)\n","Test: [ 160/196]  Time: 2.858s (3.726s,   68.70/s)  Loss:  0.8331 (0.8175)  Acc@1:  84.375 ( 79.794)  Acc@5:  92.969 ( 94.968)\n","Test: [ 170/196]  Time: 2.871s (3.712s,   68.96/s)  Loss:  0.5276 (0.8320)  Acc@1:  87.891 ( 79.480)  Acc@5:  97.266 ( 94.846)\n","Test: [ 180/196]  Time: 2.909s (3.716s,   68.89/s)  Loss:  1.1939 (0.8459)  Acc@1:  69.531 ( 79.176)  Acc@5:  94.141 ( 94.734)\n","Test: [ 190/196]  Time: 2.879s (3.706s,   69.08/s)  Loss:  0.8760 (0.8477)  Acc@1:  75.391 ( 79.154)  Acc@5:  96.875 ( 94.723)\n"," * Acc@1 79.280 (20.720) Acc@5 94.778 (5.222)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 79.28,\n","    \"top1_err\": 20.72,\n","    \"top5\": 94.778,\n","    \"top5_err\": 5.222,\n","    \"param_count\": 85.57,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["# [False, False, False, False, False, False, False, False, False, True, True, True]\n","!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bAfNsYqWzVc","executionInfo":{"status":"ok","timestamp":1717225054507,"user_tz":420,"elapsed":788814,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"fab61209-bbed-4511-d6db-df37f0f6125f"},"id":"5bAfNsYqWzVc","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-06-01 06:44:34.416762: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 06:44:34.416822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 06:44:34.423639: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-01 06:44:34.443749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-01 06:44:36.741605: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [False, False, False, False, False, False, False, False, False, True, True, True]\n","Skipping slicing for layer 0\n","Skipping slicing for layer 1\n","Skipping slicing for layer 2\n","Skipping slicing for layer 3\n","Skipping slicing for layer 4\n","Skipping slicing for layer 5\n","Skipping slicing for layer 6\n","Skipping slicing for layer 7\n","Skipping slicing for layer 8\n","Skipping slicing for layer 9\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 84463912\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 10.249s (10.249s,   24.98/s)  Loss:  0.3169 (0.3169)  Acc@1:  91.797 ( 91.797)  Acc@5:  99.609 ( 99.609)\n","Test: [  10/196]  Time: 2.800s (4.331s,   59.11/s)  Loss:  0.6768 (0.4811)  Acc@1:  82.031 ( 86.044)  Acc@5:  95.703 ( 97.798)\n","Test: [  20/196]  Time: 2.912s (4.005s,   63.91/s)  Loss:  0.4172 (0.4987)  Acc@1:  91.797 ( 85.714)  Acc@5:  97.656 ( 97.545)\n","Test: [  30/196]  Time: 2.893s (3.866s,   66.21/s)  Loss:  0.6047 (0.4623)  Acc@1:  81.250 ( 86.820)  Acc@5:  96.875 ( 97.845)\n","Test: [  40/196]  Time: 2.898s (3.857s,   66.38/s)  Loss:  0.6405 (0.5344)  Acc@1:  83.984 ( 84.813)  Acc@5:  95.703 ( 97.418)\n","Test: [  50/196]  Time: 2.829s (3.777s,   67.78/s)  Loss:  0.4985 (0.5679)  Acc@1:  87.109 ( 83.885)  Acc@5:  97.266 ( 97.227)\n","Test: [  60/196]  Time: 3.252s (3.777s,   67.78/s)  Loss:  0.9396 (0.5968)  Acc@1:  75.781 ( 83.043)  Acc@5:  93.359 ( 97.138)\n","Test: [  70/196]  Time: 3.086s (3.760s,   68.09/s)  Loss:  0.5936 (0.5861)  Acc@1:  83.594 ( 83.412)  Acc@5:  98.828 ( 97.260)\n","Test: [  80/196]  Time: 3.394s (3.785s,   67.64/s)  Loss:  1.5851 (0.6212)  Acc@1:  62.109 ( 82.808)  Acc@5:  87.109 ( 96.889)\n","Test: [  90/196]  Time: 2.865s (3.775s,   67.82/s)  Loss:  1.4205 (0.6841)  Acc@1:  65.234 ( 81.542)  Acc@5:  87.891 ( 96.265)\n","Test: [ 100/196]  Time: 4.838s (3.761s,   68.07/s)  Loss:  0.9668 (0.7528)  Acc@1:  78.906 ( 80.248)  Acc@5:  93.750 ( 95.545)\n","Test: [ 110/196]  Time: 4.148s (3.749s,   68.28/s)  Loss:  0.7144 (0.7844)  Acc@1:  80.859 ( 79.716)  Acc@5:  94.922 ( 95.305)\n","Test: [ 120/196]  Time: 4.615s (3.742s,   68.42/s)  Loss:  1.4285 (0.8141)  Acc@1:  66.406 ( 79.313)  Acc@5:  87.891 ( 94.983)\n","Test: [ 130/196]  Time: 2.925s (3.749s,   68.29/s)  Loss:  0.5472 (0.8554)  Acc@1:  87.109 ( 78.453)  Acc@5:  96.484 ( 94.579)\n","Test: [ 140/196]  Time: 4.591s (3.743s,   68.40/s)  Loss:  0.9333 (0.8723)  Acc@1:  79.297 ( 78.247)  Acc@5:  93.750 ( 94.420)\n","Test: [ 150/196]  Time: 3.790s (3.724s,   68.74/s)  Loss:  1.0642 (0.8948)  Acc@1:  77.344 ( 77.965)  Acc@5:  89.844 ( 94.130)\n","Test: [ 160/196]  Time: 3.147s (3.715s,   68.92/s)  Loss:  0.8830 (0.9058)  Acc@1:  82.031 ( 77.742)  Acc@5:  93.359 ( 94.024)\n","Test: [ 170/196]  Time: 2.856s (3.717s,   68.87/s)  Loss:  0.6647 (0.9226)  Acc@1:  85.938 ( 77.396)  Acc@5:  95.312 ( 93.862)\n","Test: [ 180/196]  Time: 3.033s (3.708s,   69.05/s)  Loss:  1.4215 (0.9378)  Acc@1:  63.281 ( 77.102)  Acc@5:  92.578 ( 93.731)\n","Test: [ 190/196]  Time: 3.223s (3.699s,   69.21/s)  Loss:  0.9007 (0.9413)  Acc@1:  76.562 ( 77.070)  Acc@5:  96.875 ( 93.680)\n"," * Acc@1 77.224 (22.776) Acc@5 93.746 (6.254)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 77.224,\n","    \"top1_err\": 22.776,\n","    \"top5\": 93.746,\n","    \"top5_err\": 6.254,\n","    \"param_count\": 84.46,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["# [False, False, False, False, False, False, False, False, True, True, True, True]\n","!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBfCcD8vWzKe","executionInfo":{"status":"ok","timestamp":1717225963605,"user_tz":420,"elapsed":787082,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"c1652178-994f-408b-f9f5-32db99231356"},"id":"nBfCcD8vWzKe","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-06-01 06:59:45.191691: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 06:59:45.191749: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 06:59:45.199875: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-01 06:59:45.219200: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-01 06:59:47.666188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [False, False, False, False, False, False, False, False, True, True, True, True]\n","Skipping slicing for layer 0\n","Skipping slicing for layer 1\n","Skipping slicing for layer 2\n","Skipping slicing for layer 3\n","Skipping slicing for layer 4\n","Skipping slicing for layer 5\n","Skipping slicing for layer 6\n","Skipping slicing for layer 7\n","Skipping slicing for layer 8\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 83357608\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 10.112s (10.112s,   25.32/s)  Loss:  0.3372 (0.3372)  Acc@1:  91.016 ( 91.016)  Acc@5:  99.219 ( 99.219)\n","Test: [  10/196]  Time: 2.716s (4.271s,   59.94/s)  Loss:  0.6586 (0.4871)  Acc@1:  83.203 ( 86.151)  Acc@5:  95.312 ( 97.763)\n","Test: [  20/196]  Time: 2.891s (4.079s,   62.77/s)  Loss:  0.4016 (0.5065)  Acc@1:  91.406 ( 85.770)  Acc@5:  97.266 ( 97.433)\n","Test: [  30/196]  Time: 2.829s (3.940s,   64.98/s)  Loss:  0.6054 (0.4697)  Acc@1:  82.812 ( 86.757)  Acc@5:  96.875 ( 97.770)\n","Test: [  40/196]  Time: 2.853s (3.848s,   66.52/s)  Loss:  0.6596 (0.5453)  Acc@1:  82.812 ( 84.604)  Acc@5:  95.703 ( 97.399)\n","Test: [  50/196]  Time: 2.849s (3.770s,   67.90/s)  Loss:  0.5075 (0.5809)  Acc@1:  86.719 ( 83.571)  Acc@5:  97.266 ( 97.204)\n","Test: [  60/196]  Time: 3.869s (3.812s,   67.16/s)  Loss:  1.0620 (0.6134)  Acc@1:  71.484 ( 82.550)  Acc@5:  91.406 ( 97.048)\n","Test: [  70/196]  Time: 2.843s (3.776s,   67.80/s)  Loss:  0.6016 (0.6041)  Acc@1:  83.594 ( 82.912)  Acc@5:  99.219 ( 97.128)\n","Test: [  80/196]  Time: 2.868s (3.768s,   67.95/s)  Loss:  1.6667 (0.6421)  Acc@1:  60.938 ( 82.253)  Acc@5:  86.328 ( 96.764)\n","Test: [  90/196]  Time: 2.890s (3.749s,   68.28/s)  Loss:  1.4756 (0.7091)  Acc@1:  63.672 ( 80.894)  Acc@5:  87.891 ( 96.012)\n","Test: [ 100/196]  Time: 5.346s (3.755s,   68.17/s)  Loss:  1.0738 (0.7834)  Acc@1:  74.219 ( 79.490)  Acc@5:  91.797 ( 95.169)\n","Test: [ 110/196]  Time: 2.856s (3.735s,   68.55/s)  Loss:  0.7614 (0.8196)  Acc@1:  78.906 ( 78.825)  Acc@5:  94.922 ( 94.848)\n","Test: [ 120/196]  Time: 4.488s (3.731s,   68.61/s)  Loss:  1.5284 (0.8532)  Acc@1:  65.234 ( 78.374)  Acc@5:  86.719 ( 94.480)\n","Test: [ 130/196]  Time: 2.898s (3.709s,   69.02/s)  Loss:  0.6173 (0.8987)  Acc@1:  84.375 ( 77.391)  Acc@5:  96.875 ( 93.956)\n","Test: [ 140/196]  Time: 3.053s (3.698s,   69.24/s)  Loss:  1.0113 (0.9186)  Acc@1:  77.734 ( 77.114)  Acc@5:  91.797 ( 93.750)\n","Test: [ 150/196]  Time: 3.801s (3.704s,   69.12/s)  Loss:  1.1313 (0.9442)  Acc@1:  76.562 ( 76.725)  Acc@5:  90.625 ( 93.421)\n","Test: [ 160/196]  Time: 3.878s (3.695s,   69.28/s)  Loss:  0.9755 (0.9553)  Acc@1:  81.250 ( 76.458)  Acc@5:  91.797 ( 93.311)\n","Test: [ 170/196]  Time: 4.297s (3.686s,   69.44/s)  Loss:  0.6927 (0.9749)  Acc@1:  85.156 ( 76.065)  Acc@5:  96.094 ( 93.154)\n","Test: [ 180/196]  Time: 3.764s (3.682s,   69.53/s)  Loss:  1.5590 (0.9919)  Acc@1:  60.547 ( 75.708)  Acc@5:  89.453 ( 93.008)\n","Test: [ 190/196]  Time: 7.012s (3.689s,   69.40/s)  Loss:  0.8974 (0.9958)  Acc@1:  76.172 ( 75.656)  Acc@5:  97.266 ( 92.987)\n"," * Acc@1 75.830 (24.170) Acc@5 93.056 (6.944)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 75.83,\n","    \"top1_err\": 24.17,\n","    \"top5\": 93.056,\n","    \"top5_err\": 6.944,\n","    \"param_count\": 83.36,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":["# [False, False, False, False, False, False, False, True, True, True, True, True]\n","!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29 --sparsity 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yqq9mhNWzFb","executionInfo":{"status":"ok","timestamp":1717226879900,"user_tz":420,"elapsed":786861,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}},"outputId":"231b5652-a9fb-4b6c-c7ad-461ebfb17148"},"id":"-yqq9mhNWzFb","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n","XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n","2024-06-01 07:15:03.020012: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 07:15:03.020068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 07:15:03.027270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-01 07:15:03.047113: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-01 07:15:05.248611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n","Torch version 2.3.0+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n","Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n","args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29, convert_sliced_model_to_coreml=False, sparsity=25)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Transformer blocks mask: [False, False, False, False, False, False, False, True, True, True, True, True]\n","Skipping slicing for layer 0\n","Skipping slicing for layer 1\n","Skipping slicing for layer 2\n","Skipping slicing for layer 3\n","Skipping slicing for layer 4\n","Skipping slicing for layer 5\n","Skipping slicing for layer 6\n","Skipping slicing for layer 7\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 82251304\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Test: [   0/196]  Time: 11.961s (11.961s,   21.40/s)  Loss:  0.3329 (0.3329)  Acc@1:  91.016 ( 91.016)  Acc@5:  99.609 ( 99.609)\n","Test: [  10/196]  Time: 2.732s (4.533s,   56.48/s)  Loss:  0.6611 (0.4901)  Acc@1:  83.203 ( 85.973)  Acc@5:  95.312 ( 97.656)\n","Test: [  20/196]  Time: 2.843s (4.082s,   62.72/s)  Loss:  0.4039 (0.5087)  Acc@1:  92.969 ( 85.603)  Acc@5:  97.266 ( 97.489)\n","Test: [  30/196]  Time: 2.824s (4.009s,   63.85/s)  Loss:  0.6172 (0.4735)  Acc@1:  82.031 ( 86.555)  Acc@5:  97.266 ( 97.770)\n","Test: [  40/196]  Time: 2.833s (3.899s,   65.66/s)  Loss:  0.6754 (0.5519)  Acc@1:  83.594 ( 84.470)  Acc@5:  95.703 ( 97.351)\n","Test: [  50/196]  Time: 2.836s (3.805s,   67.27/s)  Loss:  0.5120 (0.5904)  Acc@1:  85.938 ( 83.418)  Acc@5:  97.656 ( 97.143)\n","Test: [  60/196]  Time: 3.165s (3.775s,   67.82/s)  Loss:  1.0843 (0.6242)  Acc@1:  70.703 ( 82.281)  Acc@5:  91.406 ( 96.977)\n","Test: [  70/196]  Time: 2.840s (3.743s,   68.39/s)  Loss:  0.5948 (0.6167)  Acc@1:  85.156 ( 82.631)  Acc@5:  98.828 ( 97.046)\n","Test: [  80/196]  Time: 3.692s (3.778s,   67.76/s)  Loss:  1.7825 (0.6560)  Acc@1:  55.469 ( 81.848)  Acc@5:  84.766 ( 96.658)\n","Test: [  90/196]  Time: 2.797s (3.759s,   68.11/s)  Loss:  1.5105 (0.7264)  Acc@1:  62.891 ( 80.452)  Acc@5:  86.719 ( 95.832)\n","Test: [ 100/196]  Time: 4.485s (3.728s,   68.67/s)  Loss:  1.1331 (0.8045)  Acc@1:  71.484 ( 78.960)  Acc@5:  90.234 ( 94.922)\n","Test: [ 110/196]  Time: 2.828s (3.711s,   68.99/s)  Loss:  0.7515 (0.8428)  Acc@1:  80.078 ( 78.206)  Acc@5:  94.141 ( 94.573)\n","Test: [ 120/196]  Time: 5.119s (3.715s,   68.91/s)  Loss:  1.5955 (0.8796)  Acc@1:  64.453 ( 77.621)  Acc@5:  86.719 ( 94.176)\n","Test: [ 130/196]  Time: 2.823s (3.700s,   69.19/s)  Loss:  0.6125 (0.9247)  Acc@1:  85.547 ( 76.661)  Acc@5:  97.266 ( 93.661)\n","Test: [ 140/196]  Time: 2.887s (3.689s,   69.39/s)  Loss:  1.0593 (0.9455)  Acc@1:  78.125 ( 76.366)  Acc@5:  91.406 ( 93.451)\n","Test: [ 150/196]  Time: 2.817s (3.677s,   69.62/s)  Loss:  1.1448 (0.9730)  Acc@1:  76.953 ( 75.903)  Acc@5:  88.281 ( 93.070)\n","Test: [ 160/196]  Time: 2.828s (3.670s,   69.76/s)  Loss:  1.0588 (0.9850)  Acc@1:  78.516 ( 75.645)  Acc@5:  91.016 ( 92.942)\n","Test: [ 170/196]  Time: 2.820s (3.669s,   69.77/s)  Loss:  0.7696 (1.0063)  Acc@1:  81.250 ( 75.196)  Acc@5:  94.531 ( 92.759)\n","Test: [ 180/196]  Time: 2.825s (3.661s,   69.93/s)  Loss:  1.5993 (1.0236)  Acc@1:  60.547 ( 74.858)  Acc@5:  91.016 ( 92.602)\n","Test: [ 190/196]  Time: 3.333s (3.654s,   70.06/s)  Loss:  0.8800 (1.0287)  Acc@1:  75.781 ( 74.789)  Acc@5:  98.047 ( 92.566)\n"," * Acc@1 74.958 (25.042) Acc@5 92.650 (7.350)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 74.958,\n","    \"top1_err\": 25.042,\n","    \"top5\": 92.65,\n","    \"top5_err\": 7.35,\n","    \"param_count\": 82.25,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TP7_tuQKWy1j"},"id":"TP7_tuQKWy1j","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sF8bvU6yG_F7"],"gpuType":"T4","provenance":[{"file_id":"https://huggingface.co/damian0815/CLIP-ViT-H-14-laion2B-s32B-b79K_CoreML/blob/main/clip-to-coreml.ipynb","timestamp":1703969858294}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}