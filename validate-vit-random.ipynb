{"cells":[{"cell_type":"markdown","id":"sF8bvU6yG_F7","metadata":{"id":"sF8bvU6yG_F7"},"source":["# Connect to Drive"]},{"cell_type":"code","execution_count":2,"id":"Wkd8yo2CHDuJ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17218,"status":"ok","timestamp":1713828016563,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"},"user_tz":420},"id":"Wkd8yo2CHDuJ","outputId":"9cedc91c-3654-4146-e079-0f2b055f6a83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/colab/pytorch-image-models\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'colab/cs231n/assignments/assignment3/'\n","FOLDERNAME = 'colab/pytorch-image-models/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"code","execution_count":3,"id":"lID9DF_66UVi","metadata":{"id":"lID9DF_66UVi","executionInfo":{"status":"ok","timestamp":1713828017381,"user_tz":420,"elapsed":820,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":4,"id":"1QGlLwWxBthc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1713828017599,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"},"user_tz":420},"id":"1QGlLwWxBthc","outputId":"b3936916-1919-47ac-c293-b5170e1ef17e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}],"source":["!python --version"]},{"cell_type":"markdown","id":"ov8Evcjh4v7T","metadata":{"id":"ov8Evcjh4v7T"},"source":["# Validate Google ViT Model"]},{"cell_type":"code","execution_count":null,"id":"KEM3Kfnl44Ij","metadata":{"id":"KEM3Kfnl44Ij"},"outputs":[],"source":["!pip install -e .\n","!pip install ml_collections"]},{"cell_type":"code","execution_count":null,"id":"WZqNH-HK41G4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47161878,"status":"ok","timestamp":1713785082210,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"},"user_tz":420},"id":"WZqNH-HK41G4","outputId":"553930c9-fc73-49d0-8bb4-f56c658577d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=29)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","model.safetensors: 100% 346M/346M [00:02<00:00, 136MB/s]\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Computing Q1: 0X_batch [00:00, ?X_batch/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Computing Q1: 29X_batch [30:46, 63.68s/X_batch]\n","Rotate and slice layers\n","Computing Q2 for transformer layer 0: 29X_batch [33:42, 69.75s/X_batch]\n","Computing Q3 for transformer layer 0: 29X_batch [32:42, 67.66s/X_batch]\n","Computing Q2 for transformer layer 1: 29X_batch [31:36, 65.39s/X_batch]\n","Computing Q3 for transformer layer 1: 29X_batch [30:15, 62.62s/X_batch]\n","Computing Q2 for transformer layer 2: 29X_batch [31:10, 64.51s/X_batch]\n","Computing Q3 for transformer layer 2: 29X_batch [31:53, 66.00s/X_batch]\n","Computing Q2 for transformer layer 3: 29X_batch [31:06, 64.38s/X_batch]\n","Computing Q3 for transformer layer 3: 29X_batch [27:45, 57.44s/X_batch]\n","Computing Q2 for transformer layer 4: 29X_batch [26:44, 55.31s/X_batch]\n","Computing Q3 for transformer layer 4: 29X_batch [24:58, 51.66s/X_batch]\n","Computing Q2 for transformer layer 5: 29X_batch [23:16, 48.17s/X_batch]\n","Computing Q3 for transformer layer 5: 29X_batch [24:31, 50.74s/X_batch]\n","Computing Q2 for transformer layer 6: 29X_batch [21:43, 44.95s/X_batch]\n","Computing Q3 for transformer layer 6: 29X_batch [20:49, 43.10s/X_batch]\n","Computing Q2 for transformer layer 7: 29X_batch [19:43, 40.81s/X_batch]\n","Computing Q3 for transformer layer 7: 29X_batch [21:02, 43.55s/X_batch]\n","Computing Q2 for transformer layer 8: 29X_batch [19:00, 39.34s/X_batch]\n","Computing Q3 for transformer layer 8: 29X_batch [18:20, 37.96s/X_batch]\n","Computing Q2 for transformer layer 9: 29X_batch [17:33, 36.33s/X_batch]\n","Computing Q3 for transformer layer 9: 29X_batch [15:58, 33.06s/X_batch]\n","Computing Q2 for transformer layer 10: 29X_batch [16:47, 34.75s/X_batch]\n","Computing Q3 for transformer layer 10: 29X_batch [16:07, 33.38s/X_batch]\n","Computing Q2 for transformer layer 11: 29X_batch [16:06, 33.31s/X_batch]\n","Computing Q3 for transformer layer 11: 29X_batch [15:25, 31.90s/X_batch]\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 73768552\n","Test: [   0/196]  Time: 118.321s (118.321s,    2.16/s)  Loss:  0.3158 (0.3158)  Acc@1:  92.188 ( 92.188)  Acc@5:  99.609 ( 99.609)\n","Test: [  10/196]  Time: 2.791s (60.952s,    4.20/s)  Loss:  0.6609 (0.5011)  Acc@1:  83.203 ( 85.476)  Acc@5:  95.312 ( 97.479)\n","Test: [  20/196]  Time: 2.781s (57.572s,    4.45/s)  Loss:  0.4374 (0.5242)  Acc@1:  90.234 ( 84.952)  Acc@5:  97.656 ( 97.396)\n","Test: [  30/196]  Time: 2.777s (56.362s,    4.54/s)  Loss:  0.6476 (0.4895)  Acc@1:  82.031 ( 86.013)  Acc@5:  96.484 ( 97.669)\n","Test: [  40/196]  Time: 2.737s (56.376s,    4.54/s)  Loss:  0.6806 (0.5685)  Acc@1:  83.594 ( 83.870)  Acc@5:  95.703 ( 97.256)\n","Test: [  50/196]  Time: 5.525s (56.322s,    4.55/s)  Loss:  0.5443 (0.6084)  Acc@1:  85.547 ( 82.728)  Acc@5:  96.875 ( 96.936)\n","Test: [  60/196]  Time: 19.640s (56.609s,    4.52/s)  Loss:  1.1511 (0.6433)  Acc@1:  71.094 ( 81.711)  Acc@5:  90.234 ( 96.766)\n","Test: [  70/196]  Time: 2.796s (56.560s,    4.53/s)  Loss:  0.6163 (0.6373)  Acc@1:  83.594 ( 81.998)  Acc@5:  98.828 ( 96.831)\n","Test: [  80/196]  Time: 40.346s (56.932s,    4.50/s)  Loss:  1.9023 (0.6810)  Acc@1:  55.469 ( 81.226)  Acc@5:  85.156 ( 96.378)\n","Test: [  90/196]  Time: 79.628s (57.114s,    4.48/s)  Loss:  1.5222 (0.7598)  Acc@1:  64.453 ( 79.636)  Acc@5:  86.328 ( 95.467)\n","Test: [ 100/196]  Time: 81.093s (56.974s,    4.49/s)  Loss:  1.2987 (0.8482)  Acc@1:  68.750 ( 77.939)  Acc@5:  87.500 ( 94.396)\n","Test: [ 110/196]  Time: 115.209s (57.457s,    4.46/s)  Loss:  0.8523 (0.8954)  Acc@1:  79.297 ( 76.981)  Acc@5:  92.969 ( 93.898)\n","Test: [ 120/196]  Time: 99.929s (57.790s,    4.43/s)  Loss:  1.6972 (0.9377)  Acc@1:  60.156 ( 76.327)  Acc@5:  83.984 ( 93.434)\n","Test: [ 130/196]  Time: 56.998s (57.567s,    4.45/s)  Loss:  0.7253 (0.9880)  Acc@1:  83.594 ( 75.289)  Acc@5:  94.922 ( 92.832)\n","Test: [ 140/196]  Time: 68.925s (57.634s,    4.44/s)  Loss:  1.0657 (1.0126)  Acc@1:  76.953 ( 74.934)  Acc@5:  92.578 ( 92.556)\n","Test: [ 150/196]  Time: 70.304s (57.724s,    4.43/s)  Loss:  1.3151 (1.0458)  Acc@1:  73.828 ( 74.369)  Acc@5:  87.500 ( 92.081)\n","Test: [ 160/196]  Time: 70.913s (57.536s,    4.45/s)  Loss:  1.1970 (1.0608)  Acc@1:  75.391 ( 74.068)  Acc@5:  88.672 ( 91.921)\n","Test: [ 170/196]  Time: 49.239s (57.209s,    4.47/s)  Loss:  0.9082 (1.0843)  Acc@1:  78.125 ( 73.584)  Acc@5:  93.359 ( 91.706)\n","Test: [ 180/196]  Time: 50.997s (57.118s,    4.48/s)  Loss:  1.8609 (1.1040)  Acc@1:  55.078 ( 73.176)  Acc@5:  85.156 ( 91.510)\n","Test: [ 190/196]  Time: 38.118s (57.012s,    4.49/s)  Loss:  0.9512 (1.1120)  Acc@1:  73.828 ( 73.084)  Acc@5:  97.266 ( 91.427)\n"," * Acc@1 73.258 (26.742) Acc@5 91.506 (8.494)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 73.258,\n","    \"top1_err\": 26.742,\n","    \"top5\": 91.506,\n","    \"top5_err\": 8.494,\n","    \"param_count\": 73.77,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}],"source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 29"]},{"cell_type":"code","execution_count":null,"id":"97fuVKcVizG7","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6362474,"status":"ok","timestamp":1713807671675,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"},"user_tz":420},"id":"97fuVKcVizG7","outputId":"a9a67948-48e3-4e2c-c66f-7cff82514cec"},"outputs":[{"name":"stdout","output_type":"stream","text":["args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=58)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Computing Q1: 0X_batch [00:00, ?X_batch/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Computing Q1: 58X_batch [22:16, 23.05s/X_batch]\n","Rotate and slice layers\n","Computing Q2 for transformer layer 0: 58X_batch [22:53, 23.69s/X_batch]\n","Computing Q3 for transformer layer 0: 58X_batch [21:23, 22.12s/X_batch]\n","Computing Q2 for transformer layer 1: 58X_batch [20:04, 20.76s/X_batch]\n","Computing Q3 for transformer layer 1: 58X_batch [19:26, 20.12s/X_batch]\n","Computing Q2 for transformer layer 2: 58X_batch [18:21, 19.00s/X_batch]\n","Computing Q3 for transformer layer 2: 58X_batch [17:28, 18.08s/X_batch]\n","Computing Q2 for transformer layer 3: 58X_batch [16:31, 17.10s/X_batch]\n","Computing Q3 for transformer layer 3: 58X_batch [15:29, 16.03s/X_batch]\n","Computing Q2 for transformer layer 4: 58X_batch [15:51, 16.40s/X_batch]\n","Computing Q3 for transformer layer 4: 58X_batch [15:13, 15.74s/X_batch]\n","Computing Q2 for transformer layer 5: 58X_batch [14:45, 15.26s/X_batch]\n","Computing Q3 for transformer layer 5: 58X_batch [14:18, 14.79s/X_batch]\n","Computing Q2 for transformer layer 6: 58X_batch [13:51, 14.34s/X_batch]\n","Computing Q3 for transformer layer 6: 58X_batch [12:59, 13.43s/X_batch]\n","Computing Q2 for transformer layer 7: 58X_batch [12:33, 12.99s/X_batch]\n","Computing Q3 for transformer layer 7: 58X_batch [11:15, 11.65s/X_batch]\n","Computing Q2 for transformer layer 8: 58X_batch [10:49, 11.20s/X_batch]\n","Computing Q3 for transformer layer 8: 58X_batch [10:17, 10.65s/X_batch]\n","Computing Q2 for transformer layer 9: 58X_batch [10:06, 10.47s/X_batch]\n","Computing Q3 for transformer layer 9: 58X_batch [09:53, 10.23s/X_batch]\n","Computing Q2 for transformer layer 10: 58X_batch [09:21,  9.68s/X_batch]\n","Computing Q3 for transformer layer 10: 58X_batch [09:21,  9.69s/X_batch]\n","Computing Q2 for transformer layer 11: 58X_batch [09:36,  9.94s/X_batch]\n","Computing Q3 for transformer layer 11: 58X_batch [09:33,  9.89s/X_batch]\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 73768552\n","Test: [   0/196]  Time: 9.543s (9.543s,   26.83/s)  Loss:  0.3215 (0.3215)  Acc@1:  92.188 ( 92.188)  Acc@5:  99.609 ( 99.609)\n","Test: [  10/196]  Time: 2.690s (4.415s,   57.98/s)  Loss:  0.6835 (0.5033)  Acc@1:  81.641 ( 85.334)  Acc@5:  95.312 ( 97.585)\n","Test: [  20/196]  Time: 2.646s (3.930s,   65.14/s)  Loss:  0.4495 (0.5254)  Acc@1:  91.016 ( 84.952)  Acc@5:  97.266 ( 97.396)\n","Test: [  30/196]  Time: 2.701s (3.823s,   66.97/s)  Loss:  0.6531 (0.4916)  Acc@1:  82.031 ( 85.975)  Acc@5:  96.484 ( 97.681)\n","Test: [  40/196]  Time: 2.655s (3.715s,   68.91/s)  Loss:  0.6876 (0.5702)  Acc@1:  82.812 ( 83.870)  Acc@5:  96.094 ( 97.256)\n","Test: [  50/196]  Time: 2.664s (3.649s,   70.15/s)  Loss:  0.5519 (0.6114)  Acc@1:  84.375 ( 82.682)  Acc@5:  96.875 ( 96.967)\n","Test: [  60/196]  Time: 2.718s (3.622s,   70.68/s)  Loss:  1.0700 (0.6462)  Acc@1:  72.266 ( 81.666)  Acc@5:  90.234 ( 96.728)\n","Test: [  70/196]  Time: 2.688s (3.614s,   70.83/s)  Loss:  0.6060 (0.6409)  Acc@1:  83.594 ( 81.949)  Acc@5:  98.828 ( 96.787)\n","Test: [  80/196]  Time: 2.677s (3.603s,   71.06/s)  Loss:  1.8985 (0.6823)  Acc@1:  56.641 ( 81.255)  Acc@5:  84.766 ( 96.330)\n","Test: [  90/196]  Time: 2.677s (3.593s,   71.25/s)  Loss:  1.5757 (0.7600)  Acc@1:  62.891 ( 79.670)  Acc@5:  85.156 ( 95.403)\n","Test: [ 100/196]  Time: 3.570s (3.563s,   71.85/s)  Loss:  1.3301 (0.8480)  Acc@1:  68.750 ( 77.986)  Acc@5:  88.672 ( 94.291)\n","Test: [ 110/196]  Time: 4.811s (3.564s,   71.82/s)  Loss:  0.8592 (0.8942)  Acc@1:  78.125 ( 77.038)  Acc@5:  93.359 ( 93.859)\n","Test: [ 120/196]  Time: 2.739s (3.548s,   72.16/s)  Loss:  1.6720 (0.9341)  Acc@1:  60.938 ( 76.424)  Acc@5:  83.984 ( 93.405)\n","Test: [ 130/196]  Time: 3.479s (3.532s,   72.49/s)  Loss:  0.7575 (0.9851)  Acc@1:  82.031 ( 75.337)  Acc@5:  95.703 ( 92.820)\n","Test: [ 140/196]  Time: 3.820s (3.524s,   72.65/s)  Loss:  1.0771 (1.0098)  Acc@1:  74.609 ( 74.942)  Acc@5:  91.797 ( 92.553)\n","Test: [ 150/196]  Time: 3.458s (3.507s,   73.01/s)  Loss:  1.2855 (1.0424)  Acc@1:  74.219 ( 74.358)  Acc@5:  87.891 ( 92.079)\n","Test: [ 160/196]  Time: 4.289s (3.509s,   72.95/s)  Loss:  1.1292 (1.0556)  Acc@1:  73.438 ( 74.085)  Acc@5:  89.453 ( 91.938)\n","Test: [ 170/196]  Time: 2.932s (3.492s,   73.32/s)  Loss:  0.9294 (1.0795)  Acc@1:  78.516 ( 73.588)  Acc@5:  92.969 ( 91.712)\n","Test: [ 180/196]  Time: 2.861s (3.479s,   73.59/s)  Loss:  1.8927 (1.0987)  Acc@1:  54.297 ( 73.179)  Acc@5:  85.938 ( 91.536)\n","Test: [ 190/196]  Time: 2.825s (3.478s,   73.61/s)  Loss:  0.9377 (1.1063)  Acc@1:  74.609 ( 73.102)  Acc@5:  96.875 ( 91.455)\n"," * Acc@1 73.272 (26.728) Acc@5 91.534 (8.466)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 73.272,\n","    \"top1_err\": 26.728,\n","    \"top5\": 91.534,\n","    \"top5_err\": 8.466,\n","    \"param_count\": 73.77,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}],"source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 58"]},{"cell_type":"code","execution_count":6,"id":"5zayM-aIi1kL","metadata":{"id":"5zayM-aIi1kL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d88efb6f-5317-48af-9f1c-d0ef75dc3ad8","executionInfo":{"status":"ok","timestamp":1713853662255,"user_tz":420,"elapsed":25080873,"user":{"displayName":"Andriy Sergiyenko","userId":"15454250444236454786"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["args: Namespace(data='datasets/imagenet1k/val', data_dir=None, dataset='', split='validation', num_samples=None, dataset_download=False, class_map='', input_key=None, input_img_mode=None, target_key=None, model='vit_base_patch16_224.orig_in21k_ft_in1k', pretrained=True, workers=2, batch_size=256, img_size=None, in_chans=None, input_size=None, use_train_size=False, crop_pct=None, crop_mode=None, crop_border_pixels=None, mean=None, std=None, interpolation='', num_classes=None, gp=None, log_freq=10, checkpoint='', num_gpu=1, test_pool=False, no_prefetcher=False, pin_mem=False, channels_last=False, device='cuda', amp=False, amp_dtype='float16', amp_impl='native', tf_preprocessing=False, use_ema=False, fuser='', fast_norm=False, reparam=False, model_kwargs={}, torchscript=False, torchcompile=None, aot_autograd=False, results_file='', results_format='csv', real_labels='', valid_labels='', retry=False, use_stratified_sampler=False, use_random_sampler=True, max_batches_for_pca=116)\n","Validating in float32. AMP not enabled.\n","args.model: vit_base_patch16_224.orig_in21k_ft_in1k args.pretrained: True args.num_classes: None in_chans: 3 args.gp: None args.torchscript: False args.model_kwargs: {} args.reparam: False args.test_pool: False args.channels_last: False args.torchscript: False args.torchcompile: None args.aot_autograd: False\n","Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.orig_in21k_ft_in1k)\n","model.safetensors: 100% 346M/346M [00:01<00:00, 192MB/s]\n","[timm/vit_base_patch16_224.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model vit_base_patch16_224.orig_in21k_ft_in1k created, param count: 86567656\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 224, 224)\n","\tinterpolation: bicubic\n","\tmean: (0.5, 0.5, 0.5)\n","\tstd: (0.5, 0.5, 0.5)\n","\tcrop_pct: 0.9\n","\tcrop_mode: center\n","root_dir: datasets/imagenet1k/val args.dataset:  args.split: validation args.dataset_download: False args.tf_preprocessing: False args.class_map:  args.num_samples: None args.input_key: None input_img_mode: RGB args.target_key: None\n","args.valid_labels: \n","args.real_labels: \n","data_config['input_size']: (3, 224, 224) args.batch_size: 256 args.prefetcher: True data_config['interpolation']: bicubic data_config['mean']: (0.5, 0.5, 0.5) data_config['std']: (0.5, 0.5, 0.5) args.workers: 2 crop_pct: 0.9 data_config['crop_mode']: center args.crop_border_pixels: None args.pin_mem: False device: cuda args.tf_preprocessing: False\n","slicing model\n","Replacing layers\n","Replacing layers done\n","Fusing layernorm modules\n","Fusing layernorm modules done\n","using random sampler\n","Rotate and slice layers\n","Computing Q2 for transformer layer 9: 0X_batch [00:00, ?X_batch/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Computing Q2 for transformer layer 9: 116X_batch [1:04:33, 33.39s/X_batch]\n","Computing Q3 for transformer layer 9: 116X_batch [1:07:34, 34.95s/X_batch]\n","Computing Q2 for transformer layer 10: 116X_batch [50:28, 26.11s/X_batch]\n","Computing Q3 for transformer layer 10: 116X_batch [45:13, 23.39s/X_batch]\n","Computing Q2 for transformer layer 11: 116X_batch [38:18, 19.81s/X_batch]\n","Computing Q3 for transformer layer 11: 116X_batch [34:00, 17.59s/X_batch]\n","Rotate and slice layers done\n","Model vit_base_patch16_224.orig_in21k_ft_in1k sliced, param count: 73768552\n","Test: [   0/196]  Time: 77.728s (77.728s,    3.29/s)  Loss:  0.3218 (0.3218)  Acc@1:  92.188 ( 92.188)  Acc@5:  99.219 ( 99.219)\n","Test: [  10/196]  Time: 2.359s (39.814s,    6.43/s)  Loss:  0.6746 (0.5018)  Acc@1:  81.641 ( 85.405)  Acc@5:  95.312 ( 97.621)\n","Test: [  20/196]  Time: 2.623s (37.971s,    6.74/s)  Loss:  0.4338 (0.5240)  Acc@1:  91.797 ( 85.007)  Acc@5:  97.656 ( 97.433)\n","Test: [  30/196]  Time: 11.398s (37.388s,    6.85/s)  Loss:  0.6520 (0.4903)  Acc@1:  82.031 ( 86.001)  Acc@5:  96.484 ( 97.719)\n","Test: [  40/196]  Time: 14.158s (36.990s,    6.92/s)  Loss:  0.6747 (0.5687)  Acc@1:  83.203 ( 83.822)  Acc@5:  95.703 ( 97.304)\n","Test: [  50/196]  Time: 18.869s (36.834s,    6.95/s)  Loss:  0.5761 (0.6104)  Acc@1:  84.375 ( 82.621)  Acc@5:  96.484 ( 97.005)\n","Test: [  60/196]  Time: 28.603s (36.925s,    6.93/s)  Loss:  1.0985 (0.6447)  Acc@1:  71.484 ( 81.609)  Acc@5:  90.625 ( 96.824)\n","Test: [  70/196]  Time: 23.429s (36.757s,    6.96/s)  Loss:  0.6145 (0.6389)  Acc@1:  83.203 ( 81.954)  Acc@5:  98.828 ( 96.864)\n","Test: [  80/196]  Time: 24.215s (36.613s,    6.99/s)  Loss:  1.8793 (0.6808)  Acc@1:  55.469 ( 81.182)  Acc@5:  84.375 ( 96.417)\n","Test: [  90/196]  Time: 25.263s (36.458s,    7.02/s)  Loss:  1.5149 (0.7573)  Acc@1:  64.844 ( 79.636)  Acc@5:  85.156 ( 95.493)\n","Test: [ 100/196]  Time: 28.410s (36.361s,    7.04/s)  Loss:  1.3071 (0.8439)  Acc@1:  67.578 ( 78.001)  Acc@5:  87.891 ( 94.438)\n","Test: [ 110/196]  Time: 26.242s (36.293s,    7.05/s)  Loss:  0.8460 (0.8897)  Acc@1:  78.516 ( 77.076)  Acc@5:  93.359 ( 94.010)\n","Test: [ 120/196]  Time: 33.209s (36.312s,    7.05/s)  Loss:  1.6636 (0.9301)  Acc@1:  60.547 ( 76.466)  Acc@5:  86.328 ( 93.598)\n","Test: [ 130/196]  Time: 28.775s (36.193s,    7.07/s)  Loss:  0.7606 (0.9807)  Acc@1:  82.812 ( 75.382)  Acc@5:  94.531 ( 92.993)\n","Test: [ 140/196]  Time: 34.737s (36.135s,    7.08/s)  Loss:  1.0813 (1.0052)  Acc@1:  73.438 ( 74.964)  Acc@5:  92.578 ( 92.714)\n","Test: [ 150/196]  Time: 30.206s (36.087s,    7.09/s)  Loss:  1.3050 (1.0395)  Acc@1:  72.656 ( 74.361)  Acc@5:  88.281 ( 92.219)\n","Test: [ 160/196]  Time: 31.826s (36.079s,    7.10/s)  Loss:  1.1413 (1.0537)  Acc@1:  75.000 ( 74.076)  Acc@5:  89.844 ( 92.049)\n","Test: [ 170/196]  Time: 34.262s (36.043s,    7.10/s)  Loss:  0.9064 (1.0780)  Acc@1:  78.516 ( 73.568)  Acc@5:  92.969 ( 91.827)\n","Test: [ 180/196]  Time: 35.768s (35.971s,    7.12/s)  Loss:  1.8854 (1.0975)  Acc@1:  52.344 ( 73.189)  Acc@5:  85.156 ( 91.629)\n","Test: [ 190/196]  Time: 36.868s (35.926s,    7.13/s)  Loss:  0.9546 (1.1055)  Acc@1:  73.047 ( 73.090)  Acc@5:  96.484 ( 91.533)\n"," * Acc@1 73.268 (26.732) Acc@5 91.612 (8.388)\n","--result\n","{\n","    \"model\": \"vit_base_patch16_224.orig_in21k_ft_in1k\",\n","    \"top1\": 73.268,\n","    \"top1_err\": 26.732,\n","    \"top5\": 91.612,\n","    \"top5_err\": 8.388,\n","    \"param_count\": 73.77,\n","    \"img_size\": 224,\n","    \"crop_pct\": 0.9,\n","    \"interpolation\": \"bicubic\"\n","}\n"]}],"source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 116"]},{"cell_type":"code","execution_count":null,"id":"Uwb7O-33i1hd","metadata":{"id":"Uwb7O-33i1hd"},"outputs":[],"source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 233"]},{"cell_type":"code","execution_count":null,"id":"ywu8hWISi1er","metadata":{"id":"ywu8hWISi1er"},"outputs":[],"source":["!python validate.py datasets/imagenet1k/val --model vit_base_patch16_224.orig_in21k_ft_in1k --workers 2 --pretrained --use-random-sampler --max-batches-for-pca 467"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sF8bvU6yG_F7"],"gpuType":"T4","provenance":[{"file_id":"https://huggingface.co/damian0815/CLIP-ViT-H-14-laion2B-s32B-b79K_CoreML/blob/main/clip-to-coreml.ipynb","timestamp":1703969858294}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}